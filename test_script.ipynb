{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "file_path = \"vector_store.pkl\"\n",
    "file_name=\"paper.pdf\"\n",
    "vector_file_path = os.path.join(\"vectorStore\",str.replace(file_name, 'pdf','pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vectorStore\\\\paper.pkl'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"smollm\"\n",
    "from langchain_ollama import OllamaLLM\n",
    "model=OllamaLLM(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a joke for you: Why did the computer go to the doctor? It had a virus!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of pages loaded from the document are: 9\n",
      "\n",
      "Content of the first page:-------------------- \n",
      "\n",
      "page_content='RRCSNet:Recurrent Residual Convolutional Neural  \n",
      "Network based cloud segmentation from satellite  \n",
      "images  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Abstract— A crucial role in remote sensing applications,  \n",
      "particularly in satellite imagery analysis, is played by cloud  \n",
      "segmentation.  In this paper,  RRCSNet,  a novel  Recurrent  \n",
      "Residual Convolutional Neural Network designed for accurate  \n",
      "and efficient  cloud  segmentation.  The architecture  combines  the \n",
      "strengths  of recurrent  neural  networks  and residual  \n",
      "convolutional  neural  networks  and enhance  feature  \n",
      "representation.  The model  learns  sequential  patterns  in satellite  \n",
      "data through recurrent connections, and residual connections  \n",
      "help train  deeper  networks  by addressing  the vanishing  gradient  \n",
      "problem.  Experimental  results  on Landsat  satellite  datasets  \n",
      "prove the higher performance of RRCSNet compared to the  \n",
      "existing  cloud  segmentation  methods.  Compared  to several  \n",
      "other networks, this method establishes superior performance  \n",
      "in cloud detection.  \n",
      " \n",
      "Keywords —cloud,  shadow,  recurrent  network,  residual  \n",
      "connection,  satellite image,  deep  learning  \n",
      "I. INTRODUCTION  \n",
      "Satellite  imagery  has become  an invaluable  resource  for a \n",
      "multitude  of applications,  ranging  from  environmental  \n",
      "monitoring  to disaster  response  and urban  planning.  However,  \n",
      "the accurate interpretation of these images is often impeded by  \n",
      "the presence  of clouds,  which  can obscure  critical  information  \n",
      "and hinder  subsequent  analyses.  Cloud  segmentation  in \n",
      "satellite  images  is, therefore,  a crucial  task in remote  sensing,  \n",
      "prompting the reliability and effectiveness of downstream  \n",
      "applications.  \n",
      "Clouds and cloud shadows can hide ground information  \n",
      "and significantly limiting the quality of scene understanding.  \n",
      "In cloud  covered  images  it is difficult  to obtain  ground  \n",
      "information.  Cloud  contaminated  regions  in the remote  \n",
      "sensing images appear high intensity regions and shadow  \n",
      "covered regions appear as dark. Clouds have varying shape,  \n",
      "they move  and change  their appearance.  \n",
      "Traditional  cloud  segmentation  methods  have  met \n",
      "challenges in handling the complex and dynamic nature of  \n",
      "cloud  cover,  particularly  in the presence  of diverse  \n",
      "atmospheric  conditions.  Traditional  methods  for cloud  \n",
      "segmentation  often  struggle  with issues  such as low accuracy,  \n",
      "especially in the presence of complex cloud structures and  \n",
      "varying  atmospheric  conditions.  This necessitates  an advanced  approach  that can effectively  learn  and retain  both \n",
      "local  and global  features  from  satellite  images.  \n",
      " \n",
      " \n",
      "Fig. 1 Input  cloudy  satellite  image  \n",
      " \n",
      "Fig. 2 Ground  truth  image  \n",
      "To address this gap, RRCSNet is proposed  , a Recurrent  \n",
      "Residual  Convolutional  Neural  Network  tailored  for \n",
      "segmenting  clouds  in satellite  images.  RRCSNet  \n",
      "amalgamates the strengths of recurrent neural networks and  \n",
      "residual  convolutional  neural  networks  to effectively  enhance  \n",
      "feature  representation.  The residual  connections  facilitate  the \n",
      "training of deep networks by mitigating issues such as the  \n",
      "vanishing  gradient  problem.  \n",
      "This paper presents the architecture, design principles, of  \n",
      "RRCSNet , showcasing its superior performance compared to  \n",
      "existing cloud segmentation methodologies. The proposed  \n",
      "RRCSNet  marks  a major  breakthrough  in cloud  segmentation  \n",
      "from satellite images, providing a dependable and scalable  \n",
      "solution  with broad  applications  in earth  observation  systems.  \n",
      "II. RELATED  WORKS  \n",
      "K. K. Jena et al. [1] proposed  a Deep  Convolutional  Neural  \n",
      "Network model with many layers which extracts features  \n",
      "through  convolution  and down  sampling  operation  to classify  \n",
      "cloudy  satellite  images.  Attention  based  U-Net architecture,  is \n",
      "used to detect  clouds  by methods  proposed  by S. Singhal  et al. \n",
      "[2]. A cloud  segmentation  network  by fusing  multiscale' metadata={'source': 'paper.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader(file_name)\n",
    "pages=loader.load_and_split()\n",
    "print(f\"the number of pages loaded from the document are: {len(pages)}\\n\\nContent of the first page:{'-'*20} \\n\\n{pages[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Answer the question asked on the basis of the context provided.\n",
      "If you can not find the answer then just say \"answer is not available in the given text\n",
      "context : Here is the context\n",
      "Question : Here is the question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\" Answer the question asked on the basis of the context provided.\n",
    "If you can not find the answer then just say \"answer is not available in the given text\n",
    "context : {context}\n",
    "Question : {question}\n",
    "\"\"\"\n",
    "prompt= PromptTemplate.from_template(template=template)\n",
    "print(prompt.format(context=\"Here is the context\", question=\"Here is the question\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'context': {'title': 'Context', 'type': 'string'},\n",
       "  'question': {'title': 'Question', 'type': 'string'}},\n",
       " 'required': ['context', 'question'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain =prompt | model\n",
    "chain.input_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name I was given is Anisha\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({ \"context\":\"the name I was given is anisha\", \"question\":\"What is my name?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "embeddings=OllamaEmbeddings(model=\"smollm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\projects\\local_rag\\.venv\\Lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'docarray.index.abstract.InMemoryExactNNIndex[DocArrayDoc]'>: attribute lookup InMemoryExactNNIndex[DocArrayDoc] on docarray.index.abstract failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m vector_store\u001b[38;5;241m=\u001b[39mDocArrayInMemorySearch\u001b[38;5;241m.\u001b[39mfrom_documents(pages, embedding\u001b[38;5;241m=\u001b[39membeddings)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(vector_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <class 'docarray.index.abstract.InMemoryExactNNIndex[DocArrayDoc]'>: attribute lookup InMemoryExactNNIndex[DocArrayDoc] on docarray.index.abstract failed"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "# if os.path.exists(vector_file_path):\n",
    "#     with open(vector_file_path, \"rb\") as f:\n",
    "#         vector_store = pickle.load(f)   \n",
    "# else:\n",
    "vector_store=DocArrayInMemorySearch.from_documents(pages, embedding=embeddings)\n",
    "    # with open(vector_file_path, \"wb\") as f:\n",
    "    #     pickle.dump(vector_store, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever()\n",
    "retriever.invoke(\"What is the result of the study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = ({\n",
    "    \"context\":itemgetter(\"question\") | retriever,\n",
    "    \"question\":itemgetter(\"question\")\n",
    "    }|\n",
    "    prompt|model\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke({\"question\":\"What is the result\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[\n",
    "    \"What is the title of the paper\", \n",
    "    \"How many authors are there in the paper\",\n",
    "    \"what is the plateform used to run the experiment\", \n",
    "    \"summerize the methodology\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"question: {question}\")\n",
    "    print(f\"Answer:{chain.invoke({'question':question})}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
